## 需求确认（按你最新说明）
- 发送给 AI 时，把“当前时间（精确到秒）”**拼接到用户本次消息文本里**（不放 system）。
- 该时间**不落库**，也不在前端渲染。

## 具体实现点
### 1) 后端：仅修改模型入参，不改落库内容
- 仍保持 `chat.py` 里写入数据库的 `user_message.content = request.message`（或现有兜底文本）不变。
- 只在 `ChatService.astream_chat_with_model` 里构造“发给模型的用户消息文本”时追加时间：
  - `now_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')`
  - `user_text_to_model = f"{user_text}\n\n当前时间：{now_str}"`
  - 如果 `user_text` 为空（例如仅发附件），先用现有兜底文案填充，再追加时间。

### 2) 覆盖两条模型调用链路
- **多模态（图片/视频）**：`parts.append({"type":"text","text": user_text_to_model})`
- **非多模态**：保持当前 prompt/chain 结构不变，只把 `chain.astream({... "message": user_text_to_model})` 的入参替换为拼接后的文本。
  - 位置参考：[chat_services.py](file:///f:/aaa_desktop_file/xunji/xunji-backup/app/services/chat_services.py#L349-L388)

## 测试计划（尽量不依赖真实模型）
- 增加一个小的纯函数/方法（例如 `_build_user_text_with_time(text: str) -> str`），专门负责拼接 `当前时间：YYYY-MM-DD HH:MM:SS`。
- pytest：断言输出包含时间格式（正则匹配到秒），并且原始用户文本仍在前部。
  - 这样不需要跑 LangChain/OpenAI 调用，也不会引入 key 依赖。

## 交付效果
- 模型每次都会在“用户本次消息”里看到当前时间（秒级）。
- 数据库不记录该时间，前端也不会展示。